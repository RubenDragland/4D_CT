{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The purpose of this notebook is to illustrate the necessary workflow and programming to process, reconstruct, and finally enhance golden ratio sampled CT scans.\n",
    "Nothing in this notebook wil run. Instead, the important steps, scripts, classes, and functions are displayed.\n",
    "\n",
    "Unfortunately, it would not be very readable to go more in-depth than what is here currently presented. The underlying mechanisms can be found in the respective folders."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Golden Ratio Sampled Projections\n",
    "\n",
    "The first step is to process the obtained projections. \n",
    "\n",
    "Assuming several CT scans have been obtained during the same day, it might be beneficial to apply parallelisation.\n",
    "\n",
    "DynamicProjectionsEQNR is a defined class for reading all folders with projections, performing corrections, finding AoR, rotating the projections, and\n",
    "initiating a geometry object that can read the scanning settings.\n",
    "\n",
    "The processed projections are stored to .h5-format using h5py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def func(root, expname, oroot, num_proj, nrevs, correction, geometry, roi):\n",
    "    preprocess = DynamicProjectionsEQNR(\n",
    "        root,\n",
    "        expname,\n",
    "        oroot,\n",
    "        num_proj,\n",
    "        nrevs=nrevs,\n",
    "        correction_parent=correction,\n",
    "        geometry=geometry,\n",
    "        roi=roi,\n",
    "    )\n",
    "\n",
    "    preprocess()\n",
    "\n",
    "\n",
    "def main():\n",
    "    main_root = r\"/media/nfs/qnap/home/rubensd/RSD20230509\"\n",
    "    names = [\n",
    "        \"RSD20230509_hourglassV3_13proj\",\n",
    "        \"RSD20230509_samplingV3_sandstone_6favg\",\n",
    "        \"RSD20230509_sandstoneV3_12favg\",\n",
    "        \"RSD20230509_sandstoneV3_24favg\",\n",
    "    ]\n",
    "    roots = [os.path.join(main_root, name) for name in names]\n",
    "    roots.append(r\"/media/nfs/qnap/home/rubensd/RSD20230428_standard_sandstone\")\n",
    "    main_oroot = r\"/media/disks/disk2/CT-data/rubensd/Processed_projections/\"\n",
    "    expnames = [\n",
    "        \"hourglassV3_13_55\",\n",
    "        \"limestoneV3_17_55_6favg\",\n",
    "        \"limestoneV3_17_55_12favg\",\n",
    "        \"limestoneV3_17_55_24favg\",\n",
    "        \"limestoneV3_1440_1_std\",\n",
    "    ]\n",
    "    correction = r\"/media/nfs/qnap/home/rubensd/20230424RSD/RSD20230424_samplingV3_hourglass/Corrections\"\n",
    "    num_proj = [13, 17, 17, 17, 1440]\n",
    "    nrevs = [55, 55, 55, 55, 1]\n",
    "    geoms = [\"golden_motion.nsiprg\"] * 4\n",
    "    geoms.append(None)\n",
    "    roi = [1536, 1024]\n",
    "\n",
    "    args = [\n",
    "        [\n",
    "            roots[i],\n",
    "            expnames[i],\n",
    "            main_oroot,\n",
    "            num_proj[i],\n",
    "            nrevs[i],\n",
    "            correction,\n",
    "            geoms[i],\n",
    "            roi,\n",
    "        ]\n",
    "        for i in range(len(roots))\n",
    "    ]\n",
    "\n",
    "    with Pool() as pool:\n",
    "        pool.starmap(func, args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructing the processed projections\n",
    "\n",
    "With the processed obtained, binning might be necessary. *bin_processed_projections.py* exploits Pytorch average pooling to reduce the spatial size.\n",
    "\n",
    "The parser arguments are here included. \n",
    "\n",
    "---\n",
    "\n",
    "A python file that has the necessary steps to perform custom golden ratio reconstructions, is *reconstruct_dynamic_main.py*.\n",
    "\n",
    "Here, different files, time steps, with different number of revolutions, can be reconstructed. \n",
    "\n",
    "The core for dealing with golden ratio reconstructions is the *class EquinorDynamicCT(EquinorDataCT):* instance. \n",
    "\n",
    "It interacts with the processed projections .h5-file, stores performed reconstructions in a separate .h5-file.\n",
    "\n",
    "These reconstructions can consist of single revolutions, a custom number of revolutions, and a series (4D).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Binning of processed projections for CT reconstruction and GAN enhancement\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\"-root\", type=str, required=True, help=\"root path\")\n",
    "parser.add_argument(\n",
    "    \"-oroot\", type=str, default=\"\", required=False, help=\"output root path\"\n",
    ")\n",
    "parser.add_argument(\"-expname\", type=str, required=True, help=\"Experiment name\")\n",
    "parser.add_argument(\"-copyname\", type=str, required=True, help=\"Copy name\")\n",
    "parser.add_argument(\"-bin\", type=int, default=2, required=True, help=\"Binning factor\")\n",
    "\n",
    "! python CT/bin_processed_projections.py -root /media/nfs/qnap/home/rubensd/RSD20230509/RSD20230509_hourglassV3_13proj -expname hourglassV3_13_55 -copyname hourglassV3_13_55_2favg -bin 2\n",
    "\n",
    "\n",
    "######################\n",
    "\n",
    "\n",
    "\n",
    "from data_making import *\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    root = r\"/media/disks/disk2/CT-data/rubensd/Processed_projections/\"\n",
    "    expnames = [\n",
    "        # \"hourglassV3_13_55\",\n",
    "        \"limestoneV3_17_55_6favg\",\n",
    "        \"limestoneV3_17_55_12favg\",\n",
    "        \"limestoneV3_17_55_24favg\",\n",
    "        # \"limestoneV3_1440_1_std\",\n",
    "    ]\n",
    "    oroot = r\"/home/rubensd/Documents/DeepLearning/ReconstructionData\"\n",
    "\n",
    "    fibonaccis = [3, 3, 3, 55, 1]\n",
    "    name = \"Fibonacci3\"\n",
    "\n",
    "    for i in tqdm.trange(len(expnames)):\n",
    "        expname = expnames[i]\n",
    "        print(\"Reconstructing\", expname)\n",
    "        model = EquinorDynamicCT(root, expname, oroot, expname)\n",
    "\n",
    "        if fibonaccis[i] == 1:\n",
    "            rec = model.reconstruct_idx(idx=0, CoR=0)\n",
    "\n",
    "            model.save_custom(\n",
    "                rec, name=name, idx=0, fibonacci=fibonaccis[i], method=\"fdk\"\n",
    "            )\n",
    "        else:\n",
    "            model.reconstruct_custom(idx=0, fibonacci=fibonaccis[i], name=name, CoR=0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset for training\n",
    "\n",
    "The next step in the process is training the GAN in order to perform enhancement of undersampled reconstructions. \n",
    "\n",
    "For this, a training dataset is required. \n",
    "\n",
    "Similar classes to the one listed above were created to perform simulated data creation, and experimental data creation, respectively.\n",
    "\n",
    "*process_data* is a parent function for reconstructing all reconstruction instances in a list, and storing the HQ and LQ reconstructions in respective groups with an index equal to the length of the existing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_making as dm\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "root = r\"F:\\RawReconstructions\"\n",
    "exp_names = [\"osmoseflom_torrskan kjerne D 05b\", \"Angola_OC9_S19\", \"Berea04b\", \"TR_outcrop_sample\", \"Vuggy\"]\n",
    "phan_names = [f\"phantom_{str(i).zfill(5)}\" for i in range(1,12)]\n",
    "o_root = r\"F:\\ReconstructionDatasets\"\n",
    "o_name = \"experimental_data_factor12\"\n",
    "\n",
    "recs = [dm.EquinorReconstructions(root, name, o_root, o_name) for name in exp_names]\n",
    "recs[0].process_data(recs, n_angles=12,undersampling_factor=True )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN training\n",
    "\n",
    "For this, a hyperparameter json file is necessary, as most of the settings are determined by the dictionary stored in this file. \n",
    "\n",
    "*create_hparam.py* creates such a json-file. \n",
    "\n",
    "Training is initiated in the *gym.py*-file. For the most part, the number of epochs, the paths to different inputs etc. need to be provided. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "hparams = {\n",
    "    \"name\": \"WGAN\",\n",
    "    \"lmse\": 1,\n",
    "    \"ladv\": 10,\n",
    "    \"lperc\": 0,\n",
    "    \"psz\": 80,\n",
    "    \"mbsz\": 4,\n",
    "    \"itg\": 10,\n",
    "    \"itd\": 10,\n",
    "    \"lrateg\": 1e-5,\n",
    "    \"lrated\": 2e-5,\n",
    "    \"train_split\": 0.88,\n",
    "    \"transforms\": \"basic\",\n",
    "    \"transfer_model\": \"simV1_it00500_gen\",\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    my_path = os.path.abspath(os.path.dirname(__file__))\n",
    "\n",
    "    with open(os.path.join(my_path, \"hparams\", f\"{hparams['name']}.json\"), \"w+\") as d:\n",
    "        json.dump(hparams, d)\n",
    "\n",
    "    with open(os.path.join(my_path, \"hparams\", f\"{hparams['name']}.json\"), \"r\") as d:\n",
    "        dic = json.load(d)\n",
    "\n",
    "    print(dic)\n",
    "\n",
    "\n",
    "\n",
    "! python gym.py ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN inference\n",
    "\n",
    "With training completed, outputted model weights need to be stored in a safe place. \n",
    "\n",
    "The undersampled reconstructions may now be enhanced using the optimised generator. \n",
    "\n",
    "*inference.py* and other python files with similar names can perform this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"3DTomoGAN, load trained model and enhance reconstruction\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-modelPath\", type=str, required=True, help=\"path to model folder\"\n",
    "    )\n",
    "    parser.add_argument(\"-modelName\", type=str, required=True, help=\"name of model\")\n",
    "    parser.add_argument(\"-dataFolder\", type=str, required=True, help=\"Rec folder\")\n",
    "    parser.add_argument(\"-dataName\", type=str, required=True, help=\"Rec name\")\n",
    "    parser.add_argument(\"-keyInput\", type=str, required=True, help=\"keyInput\")\n",
    "    parser.add_argument(\n",
    "        \"-keyTarget\", type=str, required=False, default=\"gt\", help=\"keyTarget\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-focus\", type=int, required=False, nargs=\"+\", default=0, help=\"Centre RoI\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-dims\", type=int, required=False, nargs=\"+\", default=0, help=\"Dimensions\"\n",
    "    )\n",
    "\n",
    "    args, unparsed = parser.parse_known_args()\n",
    "\n",
    "    # Run Enhancement\n",
    "\n",
    "    enhance(\n",
    "        args.modelPath,\n",
    "        args.modelName,\n",
    "        args.dataFolder,\n",
    "        args.dataName,\n",
    "        args.keyInput,\n",
    "        key_target=args.keyTarget,\n",
    "        focus=args.focus,\n",
    "        dims=args.dims,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "Performed in Jupyter Notebooks. \n",
    "\n",
    "Utilising quality metrics defined in the *utils.py*-file. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final remarks\n",
    "\n",
    "These are, very shortly summarised, the main steps of the derived technique for GAN-enhanced Golden ratio sampled temporal CT. \n",
    "\n",
    "Additional depth can be found in the source code, but readability has not been prioritised; at least not at this current time. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
